{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#Elements of Text\n",
        "We will learn about different units of text data for analysis, \\\n",
        "how to parse the input data and retrieve the units, etc. \\\n",
        "We will also talk about basic preprocessing steps to clean text data."
      ],
      "metadata": {
        "id": "ftCnU0iImVPv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Basic Text/String Operations"
      ],
      "metadata": {
        "id": "3DmEe2K0Qbm1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text = 'Life is Beautiful'\n",
        "text = \"Life is Beautiful\"\n",
        "text = '''Life is Beautiful'''\n",
        "text = \"\"\"Life is Beautiful\"\"\""
      ],
      "metadata": {
        "id": "FoAo1H9dQf97"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Why do we need ', \", and \"\"\"?"
      ],
      "metadata": {
        "id": "USZc5Vu0Rj_w"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's see some basic string operations on a snippet from Trump-Biden debate transcript."
      ],
      "metadata": {
        "id": "pj95m_jJR_2e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "doc = \"\"\"WELKER: Good evening from Belmont University in Nashville, Tennessee. I’m Kristen Welker of NBC News and I welcome you to the final 2020 presidential debate between President Donald J. Trump and former Vice President Joe Biden. Tonight’s debate is sponsored by The Commission on Presidential Debates. It is conducted under health and safety protocols designed by the commission’s health security advisor. The audience here in the hall has promised to remain silent. No cheers, boos or other interruptions except right now, as we welcome to the stage former Vice President Joe Biden and President Donald J. Trump.\n",
        "\n",
        "And I do want to say a very good evening to both of you. This debate will cover six major topics. At the beginning of each section, each candidate will have two minutes, uninterrupted, to answer my first question. The debate commission will then turn on their microphone only when it is their turn to answer, and the commission will turn it off exactly when the two minutes have expired. After that, both microphones will remain on, but on behalf of the voters, I’m going to ask you to please speak one at a time. The goal is for you to hear each other and for the American people to hear every word of what you both have to say. And so with that, if you’re ready, let’s start.\n",
        "\n",
        "And we will begin with the fight against the coronavirus. President Trump, the first question is for you. The country is heading into a dangerous new phase. More than 40,000 Americans are in the hospital tonight with COVID, including record numbers here in Tennessee. And since the two of you last shared a stage, 16,000 Americans have died from COVID. So please be specific: how would you lead the country during this next stage of the coronavirus crisis? Two minutes, uninterrupted.\n",
        "\n",
        "TRUMP: So, as you know, 2.2 million people, modeled out, were expected to die. We closed up the greatest economy in the world in order to fight this horrible disease that came from China. It’s a worldwide pandemic. It’s all over the world. You see the spikes in Europe and many other places right now. If you notice, the mortality rate is down, 85%. The excess mortality rate is way down, and much lower than almost any other country. And we’re fighting it and we’re fighting it hard. There is a spike. There was a spike in Florida, and it’s now gone. There was a very big spike in Texas, it’s now gone. There was a very big spike in Arizona, it’s now gone. And there were some spikes and surges in other places. They will soon be gone. We have a vaccine that’s coming, it’s ready. It’s going to be announced within weeks, and it’s going to be delivered. We have Operation Warp Speed, which is the military, is going to distribute the vaccine. I can tell you from personal experience that I was in the hospital, I had it. And I got better and I will tell you that I had something that they gave me — a therapeutic, I guess they would call it. Some people could say it was a cure. But I was in for a short period of time and I got better very fast or I wouldn’t be here tonight. And now they say I’m immune. Whether it’s four months or a lifetime, nobody’s been able to say that, but I’m immune. More and more people are getting better. We have a problem that’s a worldwide problem. This is a worldwide problem, but I’ve been congratulated by the heads of many countries on what we’ve been able to do with the — if you take a look at what we’ve done in terms of goggles and masks and gowns and everything else, and in particular, ventilators. We’re now making ventilators. All over the world, thousands and thousands a month, distributing them all over the world, it will go away and as I say, we’re rounding the turn, we’re rounding the corner, it’s going away.\n",
        "\n",
        "WELKER: OK, former Vice President Biden, to you, how would you lead the country out of this crisis? You have two minutes uninterrupted.\n",
        "\n",
        "BIDEN: 220,000 Americans dead. If you hear nothing else I say tonight, hear this. Anyone who’s responsible for not taking control — in fact, not saying, I take no responsibility, initially — anyone who is responsible for that many deaths should not remain as President of the United States of America. We’re in a situation where there are thousands of deaths a day, a thousand deaths a day. And there are over 70,000 new cases per day. Compared to what’s going on in Europe, as the New England Medical Journal said, they’re starting from a very low rate. We’re starting from a very high rate. The expectation is we’ll have another 200,000 Americans dead by the time, between now and the end of the year. If we just wore these masks — the President’s own advisors have told him — we could save 100,000 lives. And we’re in a circumstance where the President, thus far, still has no plan. No comprehensive plan. What I would do is make sure we have everyone encouraged to wear a mask, all the time. I would make sure we move in the direction of rapid testing, investing in rapid testing. I would make sure that we set up national standards as to how to open up schools and open up businesses so they can be safe, and give them the wherewithal and financial resources to be able to do that. We’re in a situation now where the New England Medical Journal — one of the serious, most serious journals in the whole world — said for the first time ever that this, the way this President has responded to this crisis has been absolutely tragic. And so folks, I will take care of this, I will end this, I will make sure we have a plan.\n",
        "\n",
        "WELKER: President Trump, I’d like to follow up with you and your comments. You talked about taking a therapeutic. I assume you’re referencing Regeneron. You also said a vaccine will be coming within weeks. Is that a guarantee?\n",
        "\n",
        "TRUMP: No, it’s not a guarantee but it will be by the end of the year, but I think it has a good chance. There are two companies, I think, within a matter of weeks, and it will be distributed very quickly.\n",
        "\n",
        "WELKER: Can you tell us which companies?\n",
        "\n",
        "TRUMP: Johnson and Johnson is doing very well. Moderna is doing very well. Pfizer is doing very well, and we have numerous others. And then we also have others that we’re working on very closely with other countries, in particular Europe.\n",
        "\n",
        "WELKER: Let me follow up with you, and because this is new information — you have said a vaccine is coming soon, within weeks now. Your own officials say it could take well into 2021 at the earliest for enough Americans to get vaccinated, and even then they say the country will be wearing masks and distancing into 2022. Is your timeline realistic?\n",
        "\n",
        "TRUMP: No, I think my timeline is going to be more accurate. I don’t know that they’re counting on the military the way I do, but we have our generals lined up, one in particular, that’s the head of logistics. And this is a very easy distribution for him. He’s ready to go as soon as we have the vaccine, and we expect to have 100 million vials as soon as we have the vaccine, he’s ready to go.\n",
        "\n",
        "WELKER: Vice President Biden, your reaction? Just 40% of Americans say they would definitely agree to take a coronavirus vaccine if it was approved by the government. What steps would you take to give Americans confidence in a vaccine if it were approved?\n",
        "\n",
        "BIDEN: Make sure it’s totally transparent. Have the scientific world see it, know it, look at it, go through all the processes. And by the way, this is the same fellow who told you this is going to end by Easter last time. This the same fellow who told you that, don’t worry, we’re going to end this by the summer. We’re about to go into a dark winter, a dark winter, and he has no clear plan and there’s no prospect that there’s going to be a vaccine available for the majority of the American people before the middle of next year.\"\"\""
      ],
      "metadata": {
        "id": "3IfG11yyRpxq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Splitting string into substrings."
      ],
      "metadata": {
        "id": "4DfcVxC2hmsr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "paragraphs = doc.split('\\n\\n')\n",
        "paragraphs"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "503vEjHFhsm4",
        "outputId": "79ec3dac-94a6-44e4-d69b-4ddfd1136b92"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['WELKER: Good evening from Belmont University in Nashville, Tennessee. I’m Kristen Welker of NBC News and I welcome you to the final 2020 presidential debate between President Donald J. Trump and former Vice President Joe Biden. Tonight’s debate is sponsored by The Commission on Presidential Debates. It is conducted under health and safety protocols designed by the commission’s health security advisor. The audience here in the hall has promised to remain silent. No cheers, boos or other interruptions except right now, as we welcome to the stage former Vice President Joe Biden and President Donald J. Trump.',\n",
              " 'And I do want to say a very good evening to both of you. This debate will cover six major topics. At the beginning of each section, each candidate will have two minutes, uninterrupted, to answer my first question. The debate commission will then turn on their microphone only when it is their turn to answer, and the commission will turn it off exactly when the two minutes have expired. After that, both microphones will remain on, but on behalf of the voters, I’m going to ask you to please speak one at a time. The goal is for you to hear each other and for the American people to hear every word of what you both have to say. And so with that, if you’re ready, let’s start.',\n",
              " 'And we will begin with the fight against the coronavirus. President Trump, the first question is for you. The country is heading into a dangerous new phase. More than 40,000 Americans are in the hospital tonight with COVID, including record numbers here in Tennessee. And since the two of you last shared a stage, 16,000 Americans have died from COVID. So please be specific: how would you lead the country during this next stage of the coronavirus crisis? Two minutes, uninterrupted.',\n",
              " 'TRUMP: So, as you know, 2.2 million people, modeled out, were expected to die. We closed up the greatest economy in the world in order to fight this horrible disease that came from China. It’s a worldwide pandemic. It’s all over the world. You see the spikes in Europe and many other places right now. If you notice, the mortality rate is down, 85%. The excess mortality rate is way down, and much lower than almost any other country. And we’re fighting it and we’re fighting it hard. There is a spike. There was a spike in Florida, and it’s now gone. There was a very big spike in Texas, it’s now gone. There was a very big spike in Arizona, it’s now gone. And there were some spikes and surges in other places. They will soon be gone. We have a vaccine that’s coming, it’s ready. It’s going to be announced within weeks, and it’s going to be delivered. We have Operation Warp Speed, which is the military, is going to distribute the vaccine. I can tell you from personal experience that I was in the hospital, I had it. And I got better and I will tell you that I had something that they gave me — a therapeutic, I guess they would call it. Some people could say it was a cure. But I was in for a short period of time and I got better very fast or I wouldn’t be here tonight. And now they say I’m immune. Whether it’s four months or a lifetime, nobody’s been able to say that, but I’m immune. More and more people are getting better. We have a problem that’s a worldwide problem. This is a worldwide problem, but I’ve been congratulated by the heads of many countries on what we’ve been able to do with the — if you take a look at what we’ve done in terms of goggles and masks and gowns and everything else, and in particular, ventilators. We’re now making ventilators. All over the world, thousands and thousands a month, distributing them all over the world, it will go away and as I say, we’re rounding the turn, we’re rounding the corner, it’s going away.',\n",
              " 'WELKER: OK, former Vice President Biden, to you, how would you lead the country out of this crisis? You have two minutes uninterrupted.',\n",
              " 'BIDEN: 220,000 Americans dead. If you hear nothing else I say tonight, hear this. Anyone who’s responsible for not taking control — in fact, not saying, I take no responsibility, initially — anyone who is responsible for that many deaths should not remain as President of the United States of America. We’re in a situation where there are thousands of deaths a day, a thousand deaths a day. And there are over 70,000 new cases per day. Compared to what’s going on in Europe, as the New England Medical Journal said, they’re starting from a very low rate. We’re starting from a very high rate. The expectation is we’ll have another 200,000 Americans dead by the time, between now and the end of the year. If we just wore these masks — the President’s own advisors have told him — we could save 100,000 lives. And we’re in a circumstance where the President, thus far, still has no plan. No comprehensive plan. What I would do is make sure we have everyone encouraged to wear a mask, all the time. I would make sure we move in the direction of rapid testing, investing in rapid testing. I would make sure that we set up national standards as to how to open up schools and open up businesses so they can be safe, and give them the wherewithal and financial resources to be able to do that. We’re in a situation now where the New England Medical Journal — one of the serious, most serious journals in the whole world — said for the first time ever that this, the way this President has responded to this crisis has been absolutely tragic. And so folks, I will take care of this, I will end this, I will make sure we have a plan.',\n",
              " 'WELKER: President Trump, I’d like to follow up with you and your comments. You talked about taking a therapeutic. I assume you’re referencing Regeneron. You also said a vaccine will be coming within weeks. Is that a guarantee?',\n",
              " 'TRUMP: No, it’s not a guarantee but it will be by the end of the year, but I think it has a good chance. There are two companies, I think, within a matter of weeks, and it will be distributed very quickly.',\n",
              " 'WELKER: Can you tell us which companies?',\n",
              " 'TRUMP: Johnson and Johnson is doing very well. Moderna is doing very well. Pfizer is doing very well, and we have numerous others. And then we also have others that we’re working on very closely with other countries, in particular Europe.',\n",
              " 'WELKER: Let me follow up with you, and because this is new information — you have said a vaccine is coming soon, within weeks now. Your own officials say it could take well into 2021 at the earliest for enough Americans to get vaccinated, and even then they say the country will be wearing masks and distancing into 2022. Is your timeline realistic?',\n",
              " 'TRUMP: No, I think my timeline is going to be more accurate. I don’t know that they’re counting on the military the way I do, but we have our generals lined up, one in particular, that’s the head of logistics. And this is a very easy distribution for him. He’s ready to go as soon as we have the vaccine, and we expect to have 100 million vials as soon as we have the vaccine, he’s ready to go.',\n",
              " 'WELKER: Vice President Biden, your reaction? Just 40% of Americans say they would definitely agree to take a coronavirus vaccine if it was approved by the government. What steps would you take to give Americans confidence in a vaccine if it were approved?',\n",
              " 'BIDEN: Make sure it’s totally transparent. Have the scientific world see it, know it, look at it, go through all the processes. And by the way, this is the same fellow who told you this is going to end by Easter last time. This the same fellow who told you that, don’t worry, we’re going to end this by the summer. We’re about to go into a dark winter, a dark winter, and he has no clear plan and there’s no prospect that there’s going to be a vaccine available for the majority of the American people before the middle of next year.']"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "How to separate the speaker from the speech?"
      ],
      "metadata": {
        "id": "VroptXhWUIvs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "paragraphs[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        },
        "id": "XOoBYf7jTZua",
        "outputId": "afe700e5-d0bb-40bd-885a-65d7a1202344"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'WELKER: Good evening from Belmont University in Nashville, Tennessee. I’m Kristen Welker of NBC News and I welcome you to the final 2020 presidential debate between President Donald J. Trump and former Vice President Joe Biden. Tonight’s debate is sponsored by The Commission on Presidential Debates. It is conducted under health and safety protocols designed by the commission’s health security advisor. The audience here in the hall has promised to remain silent. No cheers, boos or other interruptions except right now, as we welcome to the stage former Vice President Joe Biden and President Donald J. Trump.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Note that we set the number of splits to 1.\n",
        "# Because, we don't want to split the speech in case there is a ':' in it.\n",
        "speaker, speech = paragraphs[0].split(': ', 1)\n",
        "print(speaker)\n",
        "print(speech)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1m-r2i1_UM_p",
        "outputId": "4add2f0a-c7e4-45ea-de40-916ad9faea46"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WELKER\n",
            "Good evening from Belmont University in Nashville, Tennessee. I’m Kristen Welker of NBC News and I welcome you to the final 2020 presidential debate between President Donald J. Trump and former Vice President Joe Biden. Tonight’s debate is sponsored by The Commission on Presidential Debates. It is conducted under health and safety protocols designed by the commission’s health security advisor. The audience here in the hall has promised to remain silent. No cheers, boos or other interruptions except right now, as we welcome to the stage former Vice President Joe Biden and President Donald J. Trump.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "List of basic string operations https://www.w3schools.com/python/python_ref_string.asp"
      ],
      "metadata": {
        "id": "_9atp0ATUoLX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Read a text document from file"
      ],
      "metadata": {
        "id": "1bIOBPJowqh7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# news.txt link: https://drive.google.com/file/d/1KVzSvjIFddd8kNWoSZZnc_Q5hGqPNePe/view?usp=sharing\n",
        "with open('/content/news.txt', 'r') as file:\n",
        "  content = file.read()\n",
        "# Long document. Just printing first 500 characters.\n",
        "print (content[:500])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sO-vB35mxsHR",
        "outputId": "3562657b-13ce-491d-9e32-02cb0864c9cf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mr. Speaker. Thank you. You can smile, it’s OK. Thank you, thank you, thank you. Thank you. Please.\n",
            "Mr. Speaker. Madam Vice President. Our first lady and second gentleman. Good to see you guys up there. Members of Congress.\n",
            "And by the way, Chief Justice, I may need a court order. She gets to go to the game tomorrow, next week; I have to stay home. We got to work something out here.\n",
            "Members of the cabinet. Leaders of our military. Chief Justice, associate justices and retired justices of the Supr\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Sentence Tokenization"
      ],
      "metadata": {
        "id": "r1IXJSYOy1ap"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Simple Approach\n",
        "+ Split the document by '.' or '. '\n",
        "+ A little sophisticated would be splitting by ['.', '?', '!']"
      ],
      "metadata": {
        "id": "NRFm1PgF0Ks-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sentences = content.split('.')\n",
        "print(len(sentences))\n",
        "sentences[:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o8o-cUoJ0Obv",
        "outputId": "21b2b471-1383-400d-ec5f-9bbedfaad687"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "734\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Mr',\n",
              " ' Speaker',\n",
              " ' Thank you',\n",
              " ' You can smile, it’s OK',\n",
              " ' Thank you, thank you, thank you',\n",
              " ' Thank you',\n",
              " ' Please',\n",
              " '\\nMr',\n",
              " ' Speaker',\n",
              " ' Madam Vice President']"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Limitations\n",
        "+ '.' can be part of a word. Example: Dr., or Ph.D., or Mr.\n",
        "+ There can be consecutive '.'. For example, 'I think, um..., this is excellent.\n",
        "+ Monetary values or dates may have '.'. Example, '$101.5', '06.07.2023', 'Jan. 6'."
      ],
      "metadata": {
        "id": "uq-f4aNF6v6A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(sentences[:5])\n",
        "print('Her date of birth is Jan. 23.'.split('.'))\n",
        "print('I owe you $50.5'.split('.'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_v_SXymhtiVT",
        "outputId": "38a324eb-881a-4e8b-d2a3-1d004cbadfb9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Mr', ' Speaker', ' Thank you', ' You can smile, it’s OK', ' Thank you, thank you, thank you']\n",
            "['Her date of birth is Jan', ' 23', '']\n",
            "['I owe you $50', '5']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "####Rule-based or Machine Learning based Approach\n",
        "Importing necessary packages and models."
      ],
      "metadata": {
        "id": "h0Ki76zGz0gq"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7g2z-3wpeX3E"
      },
      "outputs": [],
      "source": [
        "import spacy\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "doc = nlp(content)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sentences = [s for s in doc.sents]\n",
        "print(len(sentences))\n",
        "sentences[:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "73Eifhy1z8CP",
        "outputId": "596dab4a-7f26-4d3c-a8e0-85a21b879fc3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "731\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Mr. Speaker.,\n",
              " Thank you.,\n",
              " You can smile, it’s OK.,\n",
              " Thank you, thank you, thank you.,\n",
              " Thank you.,\n",
              " Please.,\n",
              " Mr. Speaker.,\n",
              " Madam Vice President.,\n",
              " Our first lady and second gentleman.,\n",
              " Good to see you guys up there.]"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Word Tokenization"
      ],
      "metadata": {
        "id": "oyiaDUct8VnM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Naive Approach\n",
        "+ Split by a space ' '"
      ],
      "metadata": {
        "id": "Rp3yTu218Z3k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sentences[40]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gG1Bh544rpQV",
        "outputId": "22a78d92-1361-4dae-8839-77565bb6cc0b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "As we gather here tonight, we’re writing the next chapter in the great American story, a story of progress and resilience."
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(sentences[40].text.split(' '))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pyokYtUnzzim",
        "outputId": "fb914bc1-9b0d-4183-d673-7949622836e9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['As', 'we', 'gather', 'here', 'tonight,', 'we’re', 'writing', 'the', 'next', 'chapter', 'in', 'the', 'great', 'American', 'story,', 'a', 'story', 'of', 'progress', 'and', 'resilience.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Limitations\n",
        "+ Some punctuations are not part of the word\n",
        "+ Whitespaces (space, tab, new lines \\n) are not part of the word\n",
        "+ Shortened words are kept together"
      ],
      "metadata": {
        "id": "RkaFodMq-Uv9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(sentences[0].text.split(' '))\n",
        "print(sentences[10].text.split(' '))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OrdSs7sk8g4t",
        "outputId": "9124b7b0-ac86-483d-9b32-6f86844ce803"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Mr.', 'Speaker.']\n",
            "['Members', 'of', 'Congress.\\n']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Better Approach. Rule-based or ML models."
      ],
      "metadata": {
        "id": "WlnC1NDjqpK-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print([token for token in sentences[0]])\n",
        "print([token for token in sentences[10]])\n",
        "print([token for token in sentences[40]])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xuGrX2Et-ltr",
        "outputId": "7632a403-323b-482c-ed64-1485f7e8f87d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Mr., Speaker, .]\n",
            "[Members, of, Congress, ., \n",
            "]\n",
            "[As, we, gather, here, tonight, ,, we, ’re, writing, the, next, chapter, in, the, great, American, story, ,, a, story, of, progress, and, resilience, .]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Lemmatization\n",
        "\n",
        "In linguistics, the term \"lemma\" refers to the base or dictionary form of a word. It is the form under which a word is listed in a dictionary, and it represents the canonical or citation form of that word.\n",
        "\n",
        "For example, the lemma of the word \"running\" is \"run,\" and the lemma of the word \"dogs\" is \"dog.\" Lemmas are typically used to represent the word in its most basic and uninflected form, without any prefixes, suffixes, or inflections.\n",
        "\n",
        "Lemmas are important in various linguistic analyses, such as morphological studies, where they help identify the underlying form and meaning of words. They serve as a reference point for understanding the inflectional and derivational processes that can modify a word."
      ],
      "metadata": {
        "id": "xwd8kf6F13R_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sentences[35]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bbs6nX9RciLN",
        "outputId": "57e46505-494f-42a5-fb27-0937b1cc5e14"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "I stand here tonight after we have created, with the help of many people in this room, 12 million new jobs — more jobs created in two years than any president has created in four years, because of you all, because of the American people."
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for token in sentences[35]:\n",
        "  print(token.text + \"\\t-->\\t\" + token.lemma_)"
      ],
      "metadata": {
        "id": "JV5S3Pn63YG8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2d567086-b896-42f2-b3a8-5d147f77f2ac"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "I\t-->\tI\n",
            "stand\t-->\tstand\n",
            "here\t-->\there\n",
            "tonight\t-->\ttonight\n",
            "after\t-->\tafter\n",
            "we\t-->\twe\n",
            "have\t-->\thave\n",
            "created\t-->\tcreate\n",
            ",\t-->\t,\n",
            "with\t-->\twith\n",
            "the\t-->\tthe\n",
            "help\t-->\thelp\n",
            "of\t-->\tof\n",
            "many\t-->\tmany\n",
            "people\t-->\tpeople\n",
            "in\t-->\tin\n",
            "this\t-->\tthis\n",
            "room\t-->\troom\n",
            ",\t-->\t,\n",
            "12\t-->\t12\n",
            "million\t-->\tmillion\n",
            "new\t-->\tnew\n",
            "jobs\t-->\tjob\n",
            "—\t-->\t—\n",
            "more\t-->\tmore\n",
            "jobs\t-->\tjob\n",
            "created\t-->\tcreate\n",
            "in\t-->\tin\n",
            "two\t-->\ttwo\n",
            "years\t-->\tyear\n",
            "than\t-->\tthan\n",
            "any\t-->\tany\n",
            "president\t-->\tpresident\n",
            "has\t-->\thave\n",
            "created\t-->\tcreate\n",
            "in\t-->\tin\n",
            "four\t-->\tfour\n",
            "years\t-->\tyear\n",
            ",\t-->\t,\n",
            "because\t-->\tbecause\n",
            "of\t-->\tof\n",
            "you\t-->\tyou\n",
            "all\t-->\tall\n",
            ",\t-->\t,\n",
            "because\t-->\tbecause\n",
            "of\t-->\tof\n",
            "the\t-->\tthe\n",
            "American\t-->\tamerican\n",
            "people\t-->\tpeople\n",
            ".\t-->\t.\n",
            "\n",
            "\t-->\t\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Stemming\n",
        "Stemming is another technique to convert words to their root form. However, stemming is a more crude approach. It simply cuts a suffix from the words according to some predefined rules. For example, 'created', 'create', 'creating', 'creation'; all these variations have the same stem 'creat'.\n",
        "\n",
        "Note that, 'creat' is not a dictionary word.\n",
        "\n",
        "Spacy doesn't have built-in function for stemming. We are using NLTK package to demonstrate this concept. NLTK is a highly used language processing Python package."
      ],
      "metadata": {
        "id": "tX3lmDJnvoIQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "\n",
        "nltk.download('punkt')\n",
        "\n",
        "from nltk.stem import PorterStemmer\n",
        "from nltk.tokenize import word_tokenize"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fC-XdUC34XWc",
        "outputId": "dc1853b9-3f8a-4c6f-c293-d6bd50a6d44a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create an instance of the PorterStemmer\n",
        "stemmer = PorterStemmer()\n",
        "\n",
        "# Example sentence\n",
        "sentence = \"I love creating moments, running races and I ran in a race just yesterday\"\n",
        "\n",
        "# Tokenize the sentence into individual words\n",
        "words = word_tokenize(sentence)\n",
        "print(words)\n",
        "\n",
        "# Stem each word in the sentence\n",
        "stemmed_words = [stemmer.stem(word) for word in words]\n",
        "\n",
        "# Print the stemmed words\n",
        "print(stemmed_words)"
      ],
      "metadata": {
        "id": "dTrYlTTV7xgk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7db867cf-e435-41c5-a6b9-7de3e6285443"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['I', 'love', 'creating', 'moments', ',', 'running', 'races', 'and', 'I', 'ran', 'in', 'a', 'race', 'just', 'yesterday']\n",
            "['i', 'love', 'creat', 'moment', ',', 'run', 'race', 'and', 'i', 'ran', 'in', 'a', 'race', 'just', 'yesterday']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Differences between Lemmatization and Stemming\n",
        "\n",
        "\n",
        "*   Lemmatization follows morphological/grammatical rules of a language. On the other hand, Stemming is heuristic based; often not following the language grammar.\n",
        "*   Lemmas are grammatically correct dictionary words. Stems aren't always dictionary words. For example, 'create' is the lemma for 'creation'; 'creat' is the stem for 'creation'.\n",
        "*   Lemmatization takes more time computationally compared to stemming.\n",
        "\n"
      ],
      "metadata": {
        "id": "bC7rtZ7w54Jd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Exercise"
      ],
      "metadata": {
        "id": "22qEdXie9AC_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Find all sentences where 'man' is discussed."
      ],
      "metadata": {
        "id": "kYg2BXPfDyMY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "####Naive Approach"
      ],
      "metadata": {
        "id": "StONzGtYMkke"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for sent in doc.sents:\n",
        "  if 'man' in sent.text:\n",
        "    print (sent.text)"
      ],
      "metadata": {
        "id": "mF_9QAUhEH44",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "22b568c1-d038-4cd5-828a-a8130a308da8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Our first lady and second gentleman.\n",
            "I stand here tonight after we have created, with the help of many people in this room, 12 million new jobs — more jobs created in two years than any president has created in four years, because of you all, because of the American people.\n",
            "\n",
            "That’s always been my vision of our country, and I know it’s many of yours.\n",
            "\n",
            "Too many good-paying manufacturing jobs moved overseas.\n",
            "Once-thriving cities and towns that many of you represent became shadows of what they used to be.\n",
            "\n",
            "We’ve already created, with your help, 800,000 good-paying manufacturing jobs, the fastest growth in 40 years.\n",
            "\n",
            "And where is it written — where is it written that America can’t lead the world in manufacturing?\n",
            "For too many decades, we imported projects and exported jobs.\n",
            "\n",
            "We’ve already created — we’ve already created 800,000 new manufacturing jobs without this law, before the law kicks in.\n",
            "\n",
            "That’s going to come from companies that have announced more than $300 billion in investment in American manufacturing over the next few years.\n",
            "\n",
            "Jobs paying an average of $130,000 a year, and many do not require a college degree.\n",
            "\n",
            "Think about the new homes, the small businesses, the big, the medium-size businesses — so much more that’s going to be needed to support those 3,000 — those 3,000 permanent jobs in the factories that are going to be built.\n",
            "\n",
            "While I was there, I met a young woman named Saria, who is here tonight.\n",
            "Four hundred thousand school and child care centers, so every child in America, every child in America can drink the water instead of having permanent damage to their brain.\n",
            "\n",
            "No parent should have to drive by a McDonald’s parking lot to help them do their homework online with their kids, which many thousands were doing across the country.\n",
            "\n",
            "So many of you listening to me tonight, I know you feel it.\n",
            "So many of you felt like you’ve just simply been forgotten.\n",
            "Amid the economic upheaval of the past four decades, too many people have been left behind and treated like they’re invisible.\n",
            "\n",
            "For example, too many of you lay in bed at night like my dad did, staring at the ceiling, wondering what in God’s name happens if your spouse gets cancer or your child gets deadly ill or something happens to you.\n",
            "\n",
            "So many things that we did are only now coming to fruition.\n",
            "Many of you, like many in my family, have cancer.\n",
            "So my plea to some of you at least in this audience: Let’s finish the job and make these savings permanent.\n",
            "I think a lot of you at home — a lot of you at home agree with me and many people that you know.\n",
            "Last year I cracked down, with the help of many of you, on foreign shipping companies that were making you pay higher prices for every good coming into the country.\n",
            "\n",
            "My administration is also taking on junk fees, those hidden surcharges too many companies use to make you pay more.\n",
            "\n",
            "Look, junk fees may not matter to the very wealthy, but they matter to most other folks in homes like the one I grew up in, like many of you did.\n",
            "As many of you personally know, there’s no words to describe the heartache or grief of losing a child.\n",
            "\n",
            "And we know we ask them in many cases to do too much — to be counselors, social workers, psychologists; responding to drug overdoses, mental health crises and so much more.\n",
            "\n",
            "And two weeks ago, during the Lunar New Year celebrations, he heard the studio door close and he saw a man standing there pointing a semiautomatic pistol at him.\n",
            "\n",
            "And in that instant, he found the courage to act and wrestled the semiautomatic pistol away from the gunman, who had already killed 11 people at another dance studio.\n",
            "We know we now have a record number of personnel working to secure the border, arresting 8,000 human smugglers, seizing over 23,000 pounds of fentanyl in just the last several months.\n",
            "\n",
            "Give every woman [inaudible] right.\n",
            "\n",
            "We made clear, and I’ve made clear in my personal conversations, which have been many, with President Xi that we seek competition, not conflict.\n",
            "\n",
            "He shared a story all too familiar to millions of Americans, and many of you in the audience.\n",
            "\n",
            "It’s personal for so many of us.\n",
            "So many of us in this audience.\n",
            "\n",
            "Joining us are Maurice and Kandice, an Irishman and a daughter of immigrants from Panama.\n",
            "\n",
            "Jill and I understand that, like so many of you.\n",
            "\n",
            "Here tonight in this chamber is the man who bears the scars of that brutal attack but is as tough and as strong and resilient as they get.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Issues?\n",
        "+ False positives: Many, permanent, manufacturing.\n",
        "+ Misses 'Man'; capial or upper case.\n",
        "\n",
        "####Better Approach"
      ],
      "metadata": {
        "id": "Cf0kfY4bEdXX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for sent in doc.sents:\n",
        "  for token in sent:\n",
        "    if token.lower_ == 'man':\n",
        "      print (sent.text)"
      ],
      "metadata": {
        "id": "hoIdZwQyE8Lk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f582418d-d1c8-4e75-cd9b-05b68375c724"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "And two weeks ago, during the Lunar New Year celebrations, he heard the studio door close and he saw a man standing there pointing a semiautomatic pistol at him.\n",
            "\n",
            "Here tonight in this chamber is the man who bears the scars of that brutal attack but is as tough and as strong and resilient as they get.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#BPE Algorithm"
      ],
      "metadata": {
        "id": "pTjOPOctWf2e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import Counter, defaultdict\n",
        "\n",
        "class BPE:\n",
        "    def __init__(self, num_merges=50):\n",
        "        self.num_merges = num_merges\n",
        "        self.bpe_codes = {}\n",
        "\n",
        "    def get_stats(self, corpus):\n",
        "        \"\"\"Count frequency of symbol pairs.\"\"\"\n",
        "        pairs = Counter()\n",
        "        for word, freq in corpus.items():\n",
        "            symbols = word.split()\n",
        "            for i in range(len(symbols) - 1):\n",
        "                pairs[(symbols[i], symbols[i+1])] += freq\n",
        "        return pairs\n",
        "\n",
        "    def merge_corpus(self, corpus, pair):\n",
        "        \"\"\"Merge the most frequent pair in all words.\"\"\"\n",
        "        bigram = \" \".join(pair)\n",
        "        replacement = \"\".join(pair)\n",
        "        new_corpus = {}\n",
        "        for word, freq in corpus.items():\n",
        "            new_word = word.replace(bigram, replacement)\n",
        "            new_corpus[new_word] = freq\n",
        "        return new_corpus\n",
        "\n",
        "    def fit(self, training_texts):\n",
        "        \"\"\"Learn BPE merges from training texts.\"\"\"\n",
        "        # Initialize corpus: split words into characters\n",
        "        corpus = Counter(\" \".join(list(word)) + \" </w>\" for word in training_texts.split())\n",
        "\n",
        "        for i in range(self.num_merges):\n",
        "            pairs = self.get_stats(corpus)\n",
        "            if not pairs:\n",
        "                break\n",
        "            best = max(pairs, key=pairs.get)\n",
        "            self.bpe_codes[best] = i\n",
        "            corpus = self.merge_corpus(corpus, best)\n",
        "\n",
        "    def encode_word(self, word):\n",
        "        \"\"\"Apply learned BPE merges to a word.\"\"\"\n",
        "        word = list(word) + [\"</w>\"]\n",
        "        while True:\n",
        "            pairs = [(word[i], word[i+1]) for i in range(len(word)-1)]\n",
        "            # Find best pair\n",
        "            candidates = {pair: self.bpe_codes[pair] for pair in pairs if pair in self.bpe_codes}\n",
        "            if not candidates:\n",
        "                break\n",
        "            best = min(candidates, key=candidates.get)\n",
        "            # Merge best pair\n",
        "            i = 0\n",
        "            new_word = []\n",
        "            while i < len(word):\n",
        "                if i < len(word)-1 and (word[i], word[i+1]) == best:\n",
        "                    new_word.append(word[i] + word[i+1])\n",
        "                    i += 2\n",
        "                else:\n",
        "                    new_word.append(word[i])\n",
        "                    i += 1\n",
        "            word = new_word\n",
        "        return word\n",
        "\n",
        "    def encode(self, text):\n",
        "        \"\"\"Encode a full sentence using BPE.\"\"\"\n",
        "        return [self.encode_word(word) for word in text.split()]\n",
        "\n",
        "\n",
        "# --- Example usage ---\n",
        "train_corpus = \"low lower lowest new newer newest renew arrange\"\n",
        "test_corpus = \"lowest newer rearrange renew\"\n",
        "\n",
        "bpe = BPE(num_merges=100)\n",
        "bpe.fit(train_corpus)\n",
        "\n",
        "print(\"Learned BPE codes:\", bpe.bpe_codes)\n",
        "print(\"Encoding test corpus:\")\n",
        "for word in test_corpus.split():\n",
        "    print(word, \"->\", bpe.encode_word(word))"
      ],
      "metadata": {
        "id": "eiD7Q9RaWi1a",
        "outputId": "9f9b5c10-bd0a-4995-a562-cea43b6ddda2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Learned BPE codes: {('w', 'e'): 0, ('n', 'e'): 1, ('l', 'o'): 2, ('w', '</w>'): 3, ('lo', 'we'): 4, ('r', '</w>'): 5, ('s', 't'): 6, ('st', '</w>'): 7, ('ne', 'w</w>'): 8, ('ne', 'we'): 9, ('lo', 'w</w>'): 10, ('lowe', 'r</w>'): 11, ('lowe', 'st</w>'): 12, ('newe', 'r</w>'): 13, ('newe', 'st</w>'): 14, ('r', 'e'): 15, ('re', 'new</w>'): 16, ('a', 'r'): 17, ('ar', 'r'): 18, ('arr', 'a'): 19, ('arra', 'n'): 20, ('arran', 'g'): 21, ('arrang', 'e'): 22, ('arrange', '</w>'): 23}\n",
            "Encoding test corpus:\n",
            "lowest -> ['lowest</w>']\n",
            "newer -> ['newer</w>']\n",
            "rearrange -> ['re', 'arrange</w>']\n",
            "renew -> ['renew</w>']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Keywords of a Document\n",
        "+ Primarily frequency based approaches. Slight differences among the algorithms.\n",
        "+ Check TFiDF, [RAKE](https://pypi.org/project/rake-nltk/), [TEXTRANK](https://derwen.ai/docs/ptr/), [KEYBERT](https://pypi.org/project/keybert/)."
      ],
      "metadata": {
        "id": "51tpO3K4ktZK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Complete List of Spacy Token Attributes\n",
        "You have seen token.lower_ and token.lemma_ so far. Here are the complete list of token attributes https://spacy.io/api/token#attributes"
      ],
      "metadata": {
        "id": "l9ETBvpYxpjI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Python String Methods\n",
        "+ https://www.w3schools.com/python/python_ref_string.asp\n",
        "+ https://www.tutorialspoint.com/python/python_strings.htm"
      ],
      "metadata": {
        "id": "L5CTwn8hhI2d"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "2CxUOYZ7hfn5"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}